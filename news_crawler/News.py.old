import requests
from bs4 import BeautifulSoup
from fake_useragent import UserAgent
from tldextract import tldextract
import datetime
import pymysql
import jieba
import jieba.analyse
from snownlp import SnowNLP
from keybert import KeyBERT
import threading


ua = UserAgent()
usar = ua.random

headers = {'user-agent': usar}


class News:

    def __init__(self, title):
        self.Now = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        model = KeyBERT('LaBSE')
        splitted_title = " ".join(jieba.cut(title))

        keywords = model.extract_keywords(splitted_title, stop_words=[',', '，', '.', '。', '?', '？', '!', '！', '
                                          '_', '＿', '——', '－', '-', '−', '我', '你', '妳', '他', '她', '它', '祂', '是', '的', '了', '呢', '嗎', '問', '問題', '問卷', '什麼', '新聞', '分享', '討論', '這個', '那個', '哪個', '最', '爆', '傳', '驚魂', '這項', '曝', '這招', '那招', '什麼', '驚', '推'])
        keywords_str = " ".join([i[0] for i in keywords])

        same_url = 'https://news.google.com/search?q=' + \
            keywords_str+'&hl=zh-TW&gl=TW&ceid=TW%3Azh-Hant'

        self.htmlfile = requests.get(same_url, headers=headers, timeout=5)

        self.src_title = title
        self.src_keywords = keywords_str

        self.news_title = []
        self.news_content = []
        self.news_link = []

        self.news_title_kw = []
        self.news_content_kw = []

        self.sentiment_analysis = []

        self.domain = []

        objsoup = BeautifulSoup(self.htmlfile.text, "lxml")

        self.url_link_list = []
        h3_all_links = objsoup.find_all(
            'h3', {"class": "ipQwMb ekueJc RD0gLb"})
        for counter, h3_all_link in enumerate(h3_all_links):

            self.url_link_list.append(h3_all_link.find('a')['href'])
            if counter >= 11:
                break

        self.url_link_list_remove_dot = []
        for link in self.url_link_list:
            self.url_link_list_remove_dot.append(link.replace('./', '', 1))
        t = []

        for link in self.url_link_list_remove_dot:
            url = 'https://news.google.com/'+str(link)
            original_url = self.shortlink_converter(url)
            res = requests.get(original_url, headers=headers, timeout=10)

            news_url = res.request.url

            tld_result = tldextract.extract(news_url)
            domain = '{}.{}'.format(tld_result.domain, tld_result.suffix)

            t.append(threading.Thread(
                target=self.domain_check, args=(domain, news_url)))

        for thread in t:
            thread.start()
        for thread in t:
            thread.join()

    def shortlink_converter(self, url):
        resp = requests.get(url)
        return resp.url

    def toHTML(self):

        tmp = "<table>"

        tmp += "<tr><th>新聞標題</th><th>新聞標題關鍵字</th><th>新聞內文關鍵字</th><th>情感分析</th></tr>"
        for i in range(len(self.news_title)):
            tmp += "<tr>"

            tmp += "<td><img src='http://www.google.com/s2/favicons?domain=" + \
                str(self.news_link[i]) + "' />" + "<a href='" + str(
                    self.news_link[i]) + "'>" + str(self.news_title[i]) + "</a></td>"
            tmp += "<td>" + str(self.news_title_kw[i]) + "</td>"
            tmp += "<td>" + str(self.news_content_kw[i]) + "</td>"
            tmp += "<td>" + str(self.sentiment_analysis[i]) + "</td>"
            tmp += "</tr>"
        tmp += "</table>"
        return tmp

    def submitSQL(self, db_settings):

        db = pymysql.connect(**db_settings)

        cursor = db.cursor()
        for i in range(len(self.news_title)):

            sql = "INSERT INTO news_titles_contents(ID,news_title,news_content,news_link,news_title_kw,news_content_kw,sentiment_analysis,createdDate, post_title, post_kw) VALUES ('0','" + str(self.news_title[i]) + "','" + str(
                    self.news_content[i]) + "','" + str(self.news_link[i]) + "','" + str(self.news_title_kw[i]) + "','" + str(self.news_content_kw[i]) + "','" + str(self.sentiment_analysis[i]) + "','" + str(self.Now) + "', '"+str(self.src_title)+"', '"+str(self.src_keywords)+"')"

            try:
                cursor.execute(sql)

                db.commit()

            except Exception as ex:

                db.rollback()

        db.close()

    def kw(self, title, content_str):

        list_title_kw = []
        list_content_kw = []
        list_sentiment = []
        sentiment_result = "undefined"

        tags1 = " ".join(jieba.cut(title))
        kw_model = KeyBERT(model='paraphrase-multilingual-MiniLM-L12-v2')
        title_kw = kw_model.extract_keywords(tags1, keyphrase_ngram_range=(1, 1), highlight=True, stop_words=[',', '，', '.', '。', '?', '？', '!', '！', '
        for kw in title_kw:
            list_title_kw.append(kw[0])
        str1=','.join(str(x) for x in list_title_kw)

        tags2=" ".join(jieba.cut(content_str))
        content_kw=kw_model.extract_keywords(tags2, keyphrase_ngram_range=(1, 1), highlight=True, stop_words=[',', '，', '.', '。', '?', '？', '!', '！', '
        for kw in content_kw:
            list_content_kw.append(kw[0])
            s=SnowNLP(kw[0])
            list_sentiment.append(s.sentiments)
        str2=','.join(str(x) for x in list_content_kw)

        total=0
        for r in list_sentiment:
            total += r
            average=total/len(list_sentiment)
            if average >= 0.9:
                sentiment_result='絕對正面'

            elif 0.7 <= average < 0.9:
                sentiment_result='極度正面'

            elif 0.5 < average < 0.7:
                sentiment_result='相對正面'

            elif average == 0.5:
                sentiment_result == '中立'

            elif 0.3 <= average < 0.5:
                sentiment_result='相對負面'

            elif 0.1 < average < 0.3:
                sentiment_result='極度負面'

            elif average <= 0.1:
                sentiment_result='絕對負面'

            else:
                sentiment_result='錯誤發生'

        return str1, str2, sentiment_result



    def domain_check(self, domain, news_url):

        ban_set={"© 2022 BBC. BBC對外部網站內容不負責任。 閱讀了解我們對待外部鏈接的做法。", "圖像來源，Reuters", "中時新聞網對留言系統使用者發布的文字、圖片或檔案保有片面修改或移除的權利。當使用者使用本網站留言服務時，表示已詳細閱讀並完全了解，且同意配合下述規定：", "違反上述規定者，中時新聞網有權刪除留言，或者直接封鎖帳號！請使用者在發言前，務必先閱讀留言板規則，謝謝配合。", "本網站之文字", "本網站之文字、圖片及影音，非經授權，不得轉載、公開播送或公開傳輸及利用。", "省錢大作戰！超夯優惠等你GO",
                   "請繼續往下閱讀...", "不用抽 不用搶 現在用APP看新聞 保證天天中獎", "Photo Credit:", "每月一杯咖啡的金額，支持優質觀點的誕生，享有更好的閱讀體驗。", "本文經《BBC News 中文》授權轉載，原文發表於此", "更多 TVBS 報導", "更多相關新聞,'相關新聞影音", '圖／TVBS', '圖像來源，NCA', '原始連結', '點我看更多華視新聞＞＞＞', '圖像來源，Getty Images', '相關新聞影音', '[啟動LINE推播] 每日重大新聞通知', '下載法廣應用程序跟蹤國際時事'}

        break_set={'點我看更多華視新聞＞＞＞', '更多風傳媒報導', '更多 TVBS 報導'}

        match domain:
            case 'chinatimes.com':
                content_str=''
                res=requests.get(news_url)
                res.encoding='utf-8'
                if res.status_code == requests.codes.ok:
                    pass

                objsoup=BeautifulSoup(res.text, 'lxml')
                title=objsoup.find('h1', {"class": "article-title"})


                contents=objsoup.find_all('p')
                for content in contents:
                    if content.text in ban_set:
                        pass
                    else:

                        content_str += content.text
                news_title_kw, news_content_kw, sentiments_analysis=self.kw(
                    title.text, content_str)

                self.news_title.append(title.text)

                self.news_content.append(content_str)

                self.news_link.append(news_url)

                self.news_title_kw.append(news_title_kw)

                self.news_content_kw.append(news_content_kw)

                self.sentiment_analysis.append(sentiments_analysis)


            case 'cna.com.tw':
                content_str=''
                res=requests.get(news_url)
                res.encoding='utf-8'
                if res.status_code == requests.codes.ok:
                    pass

                objsoup=BeautifulSoup(res.text, 'lxml')
                title=objsoup.find('h1')

                contents=objsoup.find_all('p')

                for content in contents:
                    if content.text in ban_set:
                        pass
                    else:

                        content_str += content.text
                        news_title_kw, news_content_kw, sentiments_analysis=self.kw(
                            title.text, content_str)
                self.news_title.append(title.text)

                self.news_content.append(content_str)

                self.news_link.append(news_url)

                self.news_title_kw.append(news_title_kw)

                self.news_content_kw.append(news_content_kw)

                self.sentiment_analysis.append(sentiments_analysis)


            case 'ettoday.net':
                content_str=''
                res=requests.get(news_url)
                res.encoding='utf-8'
                if res.status_code == requests.codes.ok:
                    pass

                objsoup=BeautifulSoup(res.text, 'lxml')
                title=objsoup.find('h1', {"class": "title"})


                contents=objsoup.find(
                    'div', attrs={"class": "story"}).find_all('p')
                for content in contents:
                    if content.text in ban_set:
                        break
                    else:

                        content_str += content.text
                        news_title_kw, news_content_kw, sentiments_analysis=self.kw(
                            title.text, content_str)
                self.news_title.append(title.text)

                self.news_content.append(content_str)

                self.news_link.append(news_url)

                self.news_title_kw.append(news_title_kw)

                self.news_content_kw.append(news_content_kw)

                self.sentiment_analysis.append(sentiments_analysis)


            case 'ltn.com.tw':
                content_str=''
                res=requests.get(news_url)
                res.encoding='utf-8'
                if res.status_code == requests.codes.ok:
                    pass

                objsoup=BeautifulSoup(res.text, 'lxml')
                title=objsoup.find('h1')

                contents=objsoup.find(
                    'div', {"class": "text boxTitle boxText"}).find_all('p')

                for content in contents:
                    if content.text in ban_set:
                        break
                    else:

                        content_str += content.text
                        news_title_kw, news_content_kw, sentiments_analysis=self.kw(
                            title.text, content_str)
                self.news_title.append(title.text)

                self.news_content.append(content_str)

                self.news_link.append(news_url)

                self.news_title_kw.append(news_title_kw)

                self.news_content_kw.append(news_content_kw)

                self.sentiment_analysis.append(sentiments_analysis)


            case 'news.pts':
                content_str=''
                res=requests.get(news_url)
                res.encoding='utf-8'
                if res.status_code == requests.codes.ok:
                    pass

                objsoup=BeautifulSoup(res.text, 'lxml')
                title=objsoup.find('h1', {"class": "article-title"})


                contents=objsoup.find_all('p')
                for content in contents:

                    content_str += content.text
                    news_title_kw, news_content_kw, sentiments_analysis=self.kw(
                        title.text, content_str)
                self.news_title.append(title.text)

                self.news_content.append(content_str)

                self.news_link.append(news_url)

                self.news_title_kw.append(news_title_kw)

                self.news_content_kw.append(news_content_kw)

                self.sentiment_analysis.append(sentiments_analysis)


            case 'newtalk.tw':
                content_str=''
                res=requests.get(news_url)
                res.encoding='utf-8'
                if res.status_code == requests.codes.ok:
                    pass

                objsoup=BeautifulSoup(res.text, 'lxml')
                title=objsoup.find('h1', {"class": "content_title"})


                contents=objsoup.find(
                    'div', {"id": "news_content"}).find_all('p')
                for content in contents:

                    content_str += content.text
                    news_title_kw, news_content_kw, sentiments_analysis=self.kw(
                        title.text, content_str)
                self.news_title.append(title.text)

                self.news_content.append(content_str)

                self.news_link.append(news_url)

                self.news_title_kw.append(news_title_kw)

                self.news_content_kw.append(news_content_kw)

                self.sentiment_analysis.append(sentiments_analysis)


            case 'setn.com':
                content_str=''
                res=requests.get(news_url)
                res.encoding='utf-8'
                if res.status_code == requests.codes.ok:
                    pass

                objsoup=BeautifulSoup(res.text, 'lxml')
                title=objsoup.find('h1', {"class": "news-title-3"})


                contents=objsoup.find_all('p')
                for content in contents:

                    content_str += content.text
                    news_title_kw, news_content_kw, sentiments_analysis=self.kw(
                        title.text, content_str)
                self.news_title.append(title.text)

                self.news_content.append(content_str)

                self.news_link.append(news_url)

                self.news_title_kw.append(news_title_kw)

                self.news_content_kw.append(news_content_kw)

                self.sentiment_analysis.append(sentiments_analysis)


            case 'thenewslens.com':
                content_str=''
                res=requests.get(news_url)
                res.encoding='utf-8'
                if res.status_code == requests.codes.ok:
                    pass

                objsoup=BeautifulSoup(res.text, 'lxml')
                title=objsoup.find('h1', {"class": "article-title"})

                contents=objsoup.find(
                    'div', {"class": "article-content AdAsia"}).find_all('p')

                for content in contents:
                    if content.text in ban_set:
                        pass
                    else:

                        content_str += content.text
                        news_title_kw, news_content_kw, sentiments_analysis=self.kw(
                            title.text, content_str)
                self.news_title.append(title.text)

                self.news_content.append(content_str)

                self.news_link.append(news_url)

                self.news_title_kw.append(news_title_kw)

                self.news_content_kw.append(news_content_kw)

                self.sentiment_analysis.append(sentiments_analysis)


            case 'udn.com':
                content_str=''
                res=requests.get(news_url)
                res.encoding='utf-8'
                if res.status_code == requests.codes.ok:
                    pass

                objsoup=BeautifulSoup(res.text, 'lxml')
                try:
                    title=objsoup.find(
                        'h1', {"class": "article-content__title"})


                    contents=objsoup.find(
                        'div', {"class": "article-content__paragraph"}).find_all('p')

                    for content in contents:

                        content_str += content.text
                        news_title_kw, news_content_kw, sentiments_analysis=self.kw(
                            title.text, content_str)

                    self.news_title.append(title.text)

                    self.news_content.append(content_str)

                    self.news_link.append(news_url)

                    self.news_title_kw.append(news_title_kw)

                    self.news_content_kw.append(news_content_kw)

                    self.sentiment_analysis.append(sentiments_analysis)


                except:
                    if res.status_code == requests.codes.ok:
                        pass

                    objsoup=BeautifulSoup(res.text, 'lxml')
                    title=objsoup.find(
                        'div', {"class": "article-layout-wrapper"}).find('h1')


                    contents=objsoup.find(
                        'section', {"class": "article-body__editor"}).find_all('p')
                    for content in contents:

                        content_str += content.text
                        news_title_kw, news_content_kw, sentiments_analysis=self.kw(
                            title.text, content_str)
                    self.news_title.append(title.text)

                    self.news_content.append(content_str)

                    self.news_link.append(news_url)

                    self.news_title_kw.append(news_title_kw)

                    self.news_content_kw.append(news_content_kw)

                    self.sentiment_analysis.append(sentiments_analysis)


            case 'yahoo.com':
                content_str=''
                res=requests.get(news_url)
                res.encoding='utf-8'
                if res.status_code == requests.codes.ok:
                    pass

                try:
                    objsoup=BeautifulSoup(res.text, 'lxml')
                    title=objsoup.find(
                        'header', {"class": "caas-header"}).find('h1')

                    contents=objsoup.find(
                        'div', {"class": "caas-body"}).find_all('p')

                    for content in contents:
                        if content.text in ban_set:
                            pass
                        elif content.text in break_set:
                            break
                        else:

                            content_str += content.text
                            news_title_kw, news_content_kw, sentiments_analysis=self.kw(
                                title.text, content_str)
                    self.news_title.append(title.text)

                    self.news_content.append(content_str)

                    self.news_link.append(news_url)

                    self.news_title_kw.append(news_title_kw)

                    self.news_content_kw.append(news_content_kw)

                    self.sentiment_analysis.append(sentiments_analysis)


                except:

                    try:
                        title=objsoup.find(
                            'h1', {"data-test-locator": "headline"})

                        contents=objsoup.find(
                            'div', {"class": "caas-body"}).find_all('p')

                        for content in contents:

                            content_str += content.text
                            news_title_kw, news_content_kw, sentiments_analysis=self.kw(
                                title.text, content_str)
                        self.news_title.append(title.text)

                        self.news_content.append(content_str)

                        self.news_link.append(news_url)

                        self.news_title_kw.append(news_title_kw)

                        self.news_content_kw.append(news_content_kw)

                        self.sentiment_analysis.append(sentiments_analysis)


                    except:

                        try:
                            objsoup=BeautifulSoup(res.text, 'lxml')
                            title=objsoup.find(
                                'h1', {"class": "Fz(24px) Fw(b)"})

                            contents=objsoup.find(
                                'div', {"class": "Mt(12px) Fz(16px) Lh(1.5) C(

                            for content in contents:

                                content_str += content.text
                                news_title_kw, news_content_kw, sentiments_analysis=self.kw(
                                    title.text, content_str)
                            self.news_title.append(title.text)

                            self.news_content.append(content_str)

                            self.news_link.append(news_url)

                            self.news_title_kw.append(news_title_kw)

                            self.news_content_kw.append(news_content_kw)

                            self.sentiment_analysis.append(sentiments_analysis)


                        except:
                            pass

            case 'rfi.fr':
                content_str=''
                res=requests.get(news_url, headers=headers)
                res.encoding='utf-8'
                if res.status_code == requests.codes.ok:
                    pass

                objsoup=BeautifulSoup(res.text, 'lxml')
                title=objsoup.find('article').find('h1')


                contents=objsoup.find('article').find(
                    'div', {"class": "t-content__body u-clearfix"}).find_all('p')
                for content in contents:
                    if content.text in ban_set:
                        pass
                    else:

                        content_str += content.text
                        news_title_kw, news_content_kw, sentiments_analysis=self.kw(
                            title.text, content_str)
                self.news_title.append(title.text)

                self.news_content.append(content_str)

                self.news_link.append(news_url)

                self.news_title_kw.append(news_title_kw)

                self.news_content_kw.append(news_content_kw)

                self.sentiment_analysis.append(sentiments_analysis)


            case 'rti.org.tw':
                content_str=''
                res=requests.get(news_url)
                res.encoding='utf-8'
                if res.status_code == requests.codes.ok:
                    pass

                objsoup=BeautifulSoup(res.text, 'lxml')
                title=objsoup.find(
                    'section', {"class": "news-detail-box"}).find('h1')
                title=title.text.replace(' 用Podcast訂閱本節目 ', '').strip()


                contents=objsoup.find('article').find_all('p')
                for content in contents:

                    content_str += content.text
                    news_title_kw, news_content_kw, sentiments_analysis=self.kw(
                        title, content_str)
                self.news_title.append(title)

                self.news_content.append(content_str)

                self.news_link.append(news_url)

                self.news_title_kw.append(news_title_kw)

                self.news_content_kw.append(news_content_kw)

                self.sentiment_analysis.append(sentiments_analysis)


            case 'storm.mg':
                content_str=''
                res=requests.get(news_url)
                res.encoding='utf-8'
                if res.status_code == requests.codes.ok:
                    pass

                objsoup=BeautifulSoup(res.text, 'lxml')
                title=objsoup.find('h1', {"id": "article_title"})


                contents=objsoup.find(
                    'div', {"id": "CMS_wrapper"}).find_all('p')
                for content in contents:
                    if content.text in ban_set:
                        pass
                    elif '更多風傳媒報導' in content.text:
                        break
                    else:

                        content_str += content.text
                        news_title_kw, news_content_kw, sentiments_analysis=self.kw(
                            title.text, content_str)
                self.news_title.append(title.text)

                self.news_content.append(content_str)

                self.news_link.append(news_url)

                self.news_title_kw.append(news_title_kw)

                self.news_content_kw.append(news_content_kw)

                self.sentiment_analysis.append(sentiments_analysis)


            case 'bbc.com':
                content_str=''
                res=requests.get(news_url)
                res.encoding='utf-8'
                if res.status_code == requests.codes.ok:
                    pass

                try:
                    objsoup=BeautifulSoup(res.text, 'lxml')
                    title=objsoup.find(
                        'h1', {"class": "bbc-1tk77pb e1p3vdyi0"})


                    contents=objsoup.find_all('p')
                    for content in contents:
                        if content.text in ban_set:
                            pass
                        else:

                            content_str += content.text
                            news_title_kw, news_content_kw, sentiments_analysis=self.kw(
                                title.text, content_str)
                    self.news_title.append(title.text)

                    self.news_content.append(content_str)

                    self.news_link.append(news_url)

                    self.news_title_kw.append(news_title_kw)

                    self.news_content_kw.append(news_content_kw)

                    self.sentiment_analysis.append(sentiments_analysis)


                except:

                    title=objsoup.find(
                        'strong', {"class": "ewk8wmc0 bbc-uky4hn eglt09e1"})


                    contents=objsoup.find_all('p')
                    for content in contents:
                        if content.text in ban_set:
                            pass
                        else:

                            content_str += content.text
                            news_title_kw, news_content_kw, sentiments_analysis=self.kw(
                                title.text, content_str)
                    self.news_title.append(title.text)

                    self.news_content.append(content_str)

                    self.news_link.append(news_url)

                    self.news_title_kw.append(news_title_kw)

                    self.news_content_kw.append(news_content_kw)

                    self.sentiment_analysis.append(sentiments_analysis)


            case 'mirrormedia.mg':
                content_str=''
                res=requests.get(news_url, headers=headers)
                res.encoding='utf-8'
                if res.status_code == requests.codes.ok:
                    pass

                objsoup=BeautifulSoup(res.text, 'lxml')
                title=objsoup.find('h1', {"class": "story__title"})


                contents=objsoup.find_all(
                    'p', attrs={"class": "g-story-paragraph"})
                for content in contents:
                    if '更多內容，歡迎鏡週刊紙本雜誌、鏡週刊數位訂閱、了解內容授權資訊。' in content.text:
                        break
                    else:

                        content_str += content.text
                        news_title_kw, news_content_kw, sentiments_analysis=self.kw(
                            title.text, content_str)
                self.news_title.append(title.text)

                self.news_content.append(content_str)

                self.news_link.append(news_url)

                self.news_title_kw.append(news_title_kw)

                self.news_content_kw.append(news_content_kw)

                self.sentiment_analysis.append(sentiments_analysis)


                content_str=''
                res=requests.get(news_url, headers=headers)
                res.encoding='utf-8'
                if res.status_code == requests.codes.ok:
                    pass

                objsoup=BeautifulSoup(res.text, 'lxml')
                title=objsoup.find(
                    'div', {"class": "article-header"}).find('h1')


                contents=objsoup.find_all(
                    'div', {"class": "article-paragraph"})
                for content in contents:

                    content_str += content.text
                    news_title_kw, news_content_kw, sentiments_analysis=self.kw(
                        title.text, content_str)
                self.news_title.append(title.text)

                self.news_content.append(content_str)

                self.news_link.append(news_url)

                self.news_title_kw.append(news_title_kw)

                self.news_content_kw.append(news_content_kw)

                self.sentiment_analysis.append(sentiments_analysis)


                content_str=''
                res=requests.get(news_url, headers=headers)
                res.encoding='utf-8'
                if res.status_code == requests.codes.ok:
                    pass

                objsoup=BeautifulSoup(res.text, 'lxml')
                title=objsoup.find('h1', {"class": "wsj-article-headline"})


                contents=objsoup.find(
                    'div', {"class": "wsj-snippet-body"}).find_all('p')
                for content in contents:

                    content_str += content.text
                    news_title_kw, news_content_kw, sentiments_analysis=self.kw(
                        title.text, content_str)
                self.news_title.append(title.text)

                self.news_content.append(content_str)

                self.news_link.append(news_url)

                self.news_title_kw.append(news_title_kw)

                self.news_content_kw.append(news_content_kw)

                self.sentiment_analysis.append(sentiments_analysis)


            case'cw.com.tw':
                content_str=''
                res=requests.get(news_url, headers=headers)
                res.encoding='utf-8'
                if res.status_code == requests.codes.ok:
                    pass

                objsoup=BeautifulSoup(res.text, 'lxml')
                title=objsoup.find(
                    'div', {"class": "article__head"}).find('h1')


                contents=objsoup.find(
                    'div', {"class": "article__content py20"}).find_all('p')
                for content in contents:

                    content_str += content.text
                    news_title_kw, news_content_kw, sentiments_analysis=self.kw(
                        title.text, content_str)
                self.news_title.append(title.text)

                self.news_content.append(content_str)

                self.news_link.append(news_url)

                self.news_title_kw.append(news_title_kw)

                self.news_content_kw.append(news_content_kw)

                self.sentiment_analysis.append(sentiments_analysis)


            case 'epochtimes.com':
                content_str=''
                res=requests.get(news_url, headers=headers)
                res.encoding='utf-8'
                if res.status_code == requests.codes.ok:
                    pass

                objsoup=BeautifulSoup(res.text, 'lxml')
                title=objsoup.find('h1', {"class": "title"})


                contents=objsoup.find('div', {"id": "artbody"}).find_all('p')
                for content in contents:

                    content_str += content.text
                    news_title_kw, news_content_kw, sentiments_analysis=self.kw(
                        title.text, content_str)
                self.news_title.append(title.text)

                self.news_content.append(content_str)

                self.news_link.append(news_url)

                self.news_title_kw.append(news_title_kw)

                self.news_content_kw.append(news_content_kw)

                self.sentiment_analysis.append(sentiments_analysis)


            case 'nytimes.com':
                content_str=''
                res=requests.get(news_url, headers=headers)
                res.encoding='utf-8'
                if res.status_code == requests.codes.ok:
                    pass

                objsoup=BeautifulSoup(res.text, 'lxml')
                title=objsoup.find(
                    'div', {"class": "article-header"}).find('h1')


                contents=objsoup.find_all(
                    'div', {"class": "article-paragraph"})
                for content in contents:

                    news_title_kw, news_content_kw, sentiments_analysis=self.kw(
                        title.text, content_str)
                self.news_title.append(title.text)

                self.news_content.append(content_str)

                self.news_link.append(news_url)

                self.news_title_kw.append(news_title_kw)

                self.news_content_kw.append(news_content_kw)

                self.sentiment_analysis.append(sentiments_analysis)


            case 'wsj.com':
                content_str=''
                res=requests.get(news_url, headers=headers)
                if res.status_code == requests.codes.ok:
                    pass

                res.encoding='utf-8'
                objsoup=BeautifulSoup(res.text, 'lxml')
                title=objsoup.find('h1', {"class": "wsj-article-headline"})


                contents=objsoup.find(
                    'div', {"class": "wsj-snippet-body"}).find_all('p')
                for content in contents:

                    news_title_kw, news_content_kw, sentiments_analysis=self.kw(
                        title.text, content_str)
                self.news_title.append(title.text)

                self.news_content.append(content_str)

                self.news_link.append(news_url)

                self.news_title_kw.append(news_title_kw)

                self.news_content_kw.append(news_content_kw)

                self.sentiment_analysis.append(sentiments_analysis)


            case _:
                return "url missing!"
